{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import gc\n",
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt import space_eval\n",
    "import time\n",
    "import math\n",
    "from hyperopt.pyll.base import scope\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import lightgbm as lgb\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir= \"data/\"\n",
    "df = pd.read_csv(data_dir + \"/\" + \"creditcard.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_cols = [\"V\" + str(x) for x in range(1,29)] + [\"Amount\"]\n",
    "X = df[input_cols]\n",
    "y = df[\"Class\"]\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we can see that the dataset is heavily imbalanced as there are very samples with target class value 1 than 0.\n",
    "* We will balance dataset with SMOTE, which will oversample the samples that have minority class as output value by introducing new synthetic samples that have slightly different values of input variables from each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance dataset with SMOTE\n",
    "sm = SMOTE(random_state=7)\n",
    "X_train_bal, y_train_bal = sm.fit_resample(X_train, y_train)\n",
    "X_train_bal = pd.DataFrame(X_train_bal, columns=input_cols)\n",
    "y_train_bal = pd.Series(y_train_bal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's find out the best hyperparameters for LightGBM classifier model. I am using Hyperopt library where objective function calculates the negative f1 score as value to be minimized while searching for the optimal values of hyperparameters using Tree-structured Parzen Estimator (TPE) algorithm to explore hyperparameter space. Finally it will find out the best number of iterations with reduced learning rate for gradient boosting algorithm to be used for training on entire training dataset, before evaluating its performance against test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_evals = 300\n",
    "def find_best_params_for_lgb(X, y):\n",
    "    evaluated_point_scores = {}\n",
    "    \n",
    "    def objective(params):\n",
    "        garbage=gc.collect()\n",
    "        if (str(params) in evaluated_point_scores):\n",
    "            return evaluated_point_scores[str(params)]\n",
    "        else:          \n",
    "            kf = KFold(n_splits=2, random_state=7)\n",
    "            scores = []\n",
    "            for train_index, test_index in kf.split(X.values):                \n",
    "                X_train, X_val = X.values[train_index], X.values[test_index]\n",
    "                y_train, y_val = y.values.ravel()[train_index], y.values.ravel()[test_index]\n",
    "            \n",
    "                train_data = lgb.Dataset(X_train, \n",
    "                                label=y_train,\n",
    "                                feature_name=list(X.columns),\n",
    "                                )\n",
    "                \n",
    "                validation_data = lgb.Dataset(X_val, \n",
    "                                label=y_val,\n",
    "                                feature_name=list(X.columns),\n",
    "                                )\n",
    "                \n",
    "                evals_result = {}\n",
    "                bst = lgb.train(params, train_data, \n",
    "                                valid_sets=[train_data, validation_data], \n",
    "                                valid_names=['train', 'val'], \n",
    "                                evals_result=evals_result, \n",
    "                                num_boost_round=10000,\n",
    "                                early_stopping_rounds=100,\n",
    "                                verbose_eval=None,\n",
    "                               )\n",
    "\n",
    "                y_val_preds = np.where(bst.predict(X_val) > 0.5, 1, 0)\n",
    "                score = f1_score(y_val, y_val_preds)\n",
    "                scores.append(score)\n",
    "                \n",
    "#             print(\"Evaluating params:\")\n",
    "#             pp.pprint(params)\n",
    "            socre=np.mean(scores).item(0)\n",
    "#             print(\"f1: \" + str(score))\n",
    "            evaluated_point_scores[str(params)] = -score\n",
    "            return -score\n",
    "    param_space = {\n",
    "            'objective': hp.choice(\"objective\", [\"binary\"]),        \n",
    "            \"max_depth\": scope.int(hp.quniform(\"max_depth\", 50, 60, 1)),\n",
    "            \"learning_rate\": hp.choice(\"learning_rate\", [0.2]),\n",
    "            \"num_leaves\": scope.int(hp.quniform(\"num_leaves\", 32, 1024, 10)),   \n",
    "            \"max_bin\": scope.int(hp.quniform(\"max_bin\", 50, 250, 10)),\n",
    "            \"bagging_fraction\": hp.quniform('bagging_fraction', 0.70, 1.0, 0.05),\n",
    "            \"feature_fraction\": hp.uniform(\"feature_fraction\", 0.90, 1.0),\n",
    "            \"bagging_freq\": hp.choice(\"bagging_freq\", [1]),\n",
    "            \"lambda_l1\": hp.quniform('lambda_l1', 1, 10, 1),        \n",
    "            \"lambda_l2\": hp.quniform('lambda_l2', 1, 100, 5),\n",
    "            \"loss_function\": hp.choice(\"loss_function\", [\"binary_error\"]), \n",
    "            \"eval_metric\": hp.choice(\"eval_metric\", [\"binary_error\"]),\n",
    "            \"metric\": hp.choice(\"metric\", [\"binary_error\"]),\n",
    "            \"random_state\": hp.choice(\"random_state\", [7]),\n",
    "            \"verbose\": hp.choice(\"verbose\", [None])\n",
    "        }\n",
    "\n",
    "    best_params = space_eval(\n",
    "        param_space, \n",
    "        fmin(objective, \n",
    "             param_space, \n",
    "             algo=hyperopt.tpe.suggest,\n",
    "             max_evals=number_of_evals))    \n",
    "    \n",
    "    \n",
    "    # Finding best number of iterations with learning rate 0.1\n",
    "    best_params[\"learning_rate\"] = 0.1\n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "\n",
    "    num_iterations_array = []\n",
    "    for train_index, test_index in kf.split(X.values):                \n",
    "        X_train, X_val = X.values[train_index], X.values[test_index]\n",
    "        y_train, y_val = y.values.ravel()[train_index], y.values.ravel()[test_index]\n",
    "\n",
    "        train_data = lgb.Dataset(X_train, \n",
    "                        label=y_train,\n",
    "                        feature_name=list(X.columns),\n",
    "                        )\n",
    "\n",
    "        validation_data = lgb.Dataset(X_val, \n",
    "                        label=y_val,\n",
    "                        feature_name=list(X.columns),\n",
    "                        )\n",
    "\n",
    "        evals_result = {}\n",
    "        bst = lgb.train(best_params, train_data, \n",
    "                        valid_sets=[train_data, validation_data], \n",
    "                        valid_names=['train', 'val'], \n",
    "                        evals_result=evals_result, \n",
    "                        num_boost_round=10000,\n",
    "                        early_stopping_rounds=100,\n",
    "                        verbose_eval=None,\n",
    "                       )\n",
    "\n",
    "        num_iterations_array.append(bst.best_iteration)        \n",
    "\n",
    "    best_params[\"num_iterations\"] = int(np.mean(num_iterations_array).item(0))        \n",
    "    print (\"Best Hyperparameters found:\")\n",
    "    pp.pprint(best_params)\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/300 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/IT_BI/.local/share/virtualenvs/lgbm-pkS31_Mq/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [8:57:30<00:00, 107.50s/trial, best loss: -0.9374631489297982]  \n",
      "Best Hyperparameters found:\n",
      "{   'bagging_fraction': 0.75,\n",
      "    'bagging_freq': 1,\n",
      "    'eval_metric': 'binary_error',\n",
      "    'feature_fraction': 0.948181844012349,\n",
      "    'lambda_l1': 1.0,\n",
      "    'lambda_l2': 55.0,\n",
      "    'learning_rate': 0.1,\n",
      "    'loss_function': 'binary_error',\n",
      "    'max_bin': 60,\n",
      "    'max_depth': 54,\n",
      "    'metric': 'binary_error',\n",
      "    'num_iterations': 540,\n",
      "    'num_leaves': 40,\n",
      "    'objective': 'binary',\n",
      "    'random_state': 7,\n",
      "    'verbose': None}\n"
     ]
    }
   ],
   "source": [
    "best_params = find_best_params_for_lgb(X=X_train_bal, y=y_train_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/IT_BI/.local/share/virtualenvs/lgbm-pkS31_Mq/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "train_data = lgb.Dataset(X_train_bal.values, \n",
    "                            label=y_train_bal.values.ravel(),\n",
    "                            feature_name=list(X_train_bal.columns),\n",
    "                        )\n",
    "bst = lgb.train(best_params, train_data)\n",
    "y_probs = bst.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Calculating AUC ROC score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.990055221413246"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = roc_auc_score(y_test, y_probs)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating F1-Score with sample representing a fraudulant transaction considered as positive sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7945205479452055"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = np.where(y_probs > 0.5, 1, 0)\n",
    "f1 = f1_score(y_test, y_preds)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the model can be further improved by exploring the Hyperparameter space at more granuarlity level. This can be achieved by evaluating more combinations of hyperparameter values. This will take more execution time to explore the hyperparameter space to find the optimal parameters.\n",
    "\n",
    "Bayesian Optimization technique can also be used to narrow down search space of Hyperparams."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
